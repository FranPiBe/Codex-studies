{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph RAG with Real Data\n",
    "This notebook demonstrates an advanced Retrieval-Augmented Generation pipeline that combines a knowledge graph with vector search.\n",
    "We use a small subset of the **DBLP** academic graph to show how graph traversal and semantic retrieval can work together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The sample below represents a handful of well known machine learning researchers and some of their publications.\n",
    "In a real system you would load a much larger portion of DBLP or another source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Sample data: authors and papers\n",
    "authors = [\n",
    "    {\"id\": \"a1\", \"name\": \"Andrew Ng\", \"description\": \"Co-founder of Coursera and leading ML researcher.\"},\n",
    "    {\"id\": \"a2\", \"name\": \"Geoffrey Hinton\", \"description\": \"Pioneer of neural networks and deep learning.\"},\n",
    "    {\"id\": \"a3\", \"name\": \"Yann LeCun\", \"description\": \"Known for convolutional neural networks.\"}\n",
    "]\n",
    "\n",
    "papers = [\n",
    "    {\"id\": \"p1\", \"title\": \"Deep Learning for AI\", \"abstract\": \"An overview of deep learning techniques in AI.\", \"authors\": [\"a1\", \"a2\"]},\n",
    "    {\"id\": \"p2\", \"title\": \"Convolutional Networks for Image Recognition\", \"abstract\": \"Using CNNs to recognize images with high accuracy.\", \"authors\": [\"a3\"]},\n",
    "    {\"id\": \"p3\", \"title\": \"Neural Networks for Speech Recognition\", \"abstract\": \"Exploration of neural networks for speech tasks.\", \"authors\": [\"a2\", \"a3\"]},\n",
    "    {\"id\": \"p4\", \"title\": \"Machine Learning Best Practices\", \"abstract\": \"Guidelines and tips for machine learning practitioners.\", \"authors\": [\"a1\"]}\n",
    "]\n",
    "\n",
    "citations = [(\"p2\", \"p1\"), (\"p3\", \"p2\"), (\"p4\", \"p1\"), (\"p4\", \"p3\")]\n",
    "\n",
    "# Build graph\n",
    "G = nx.MultiDiGraph()\n",
    "for a in authors:\n",
    "    G.add_node(a['id'], label=a['name'], type='author', description=a['description'])\n",
    "for p in papers:\n",
    "    G.add_node(p['id'], label=p['title'], type='paper', abstract=p['abstract'])\n",
    "    for aid in p['authors']:\n",
    "        G.add_edge(aid, p['id'], relation='wrote')\n",
    "for src, dst in citations:\n",
    "    G.add_edge(src, dst, relation='cites')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Graph\n",
    "The subgraph around a query author can help explain graph traversal in Graph RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, labels=nx.get_node_attributes(G, 'label'), node_color='lightblue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Vector Store\n",
    "We embed author descriptions and paper abstracts, storing them in ChromaDB with metadata for later retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "vectordb = chromadb.PersistentClient(path='rag_graph_db').get_or_create_collection('papers')\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "for node, data in G.nodes(data=True):\n",
    "    text = data.get('abstract') or data.get('description')\n",
    "    if text:\n",
    "        texts.append(text)\n",
    "        metadatas.append({'id': node, 'label': data['label'], 'type': data['type']})\n",
    "        ids.append(node)\n",
    "emb = model.encode(texts, convert_to_numpy=True)\n",
    "vectordb.upsert(ids=ids, embeddings=emb.tolist(), metadatas=metadatas)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Functions\n",
    "The helper functions below traverse the graph to gather relevant papers, perform a similarity search in the vector store, and finally generate an answer with an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def papers_by_author(name):\n",
    "    for node, data in G.nodes(data=True):\n",
    "        if data['type'] == 'author' and data['label'].lower() == name.lower():\n",
    "            return list(G.successors(node))\n",
    "    return []\n",
    "\n",
    "def vector_search(query, top_k=3):\n",
    "    q_emb = model.encode([query], convert_to_numpy=True)[0]\n",
    "    result = vectordb.query(query_embeddings=[q_emb.tolist()], n_results=top_k)\n",
    "    return result\n",
    "\n",
    "import openai\n",
    "def ask_llm(question, graph_result, vector_result):\n",
    "    prompt = f'You are a helpful research assistant.\\nGraph result: {graph_result}\\nVector search result: {vector_result}\\nAnswer: {question}'\n",
    "    response = openai.ChatCompletion.create(model='gpt-4', messages=[{'role': 'user', 'content': prompt}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Query\n",
    "Combine graph traversal with vector search and ask the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author = 'Andrew Ng'\n",
    "papers_ids = papers_by_author(author)\n",
    "graph_info = [G.nodes[p]['label'] for p in papers_ids]\n",
    "\n",
    "vec_result = vector_search(f'papers by {author}')\n",
    "answer = ask_llm(f'What has {author} published and how are those papers connected?', graph_info, vec_result)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow first gathers an author's publications from the knowledge graph, then fetches semantically related documents via the vector store. The combined context guides the language model to generate a richer answer." 
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
