{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG with Multiple Search Modes\nThis notebook compares different retrieval strategies in ChromaDB and how they affect a simple RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will experiment with cosine similarity, maximal marginal relevance (MMR), and a naive hybrid approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.llms import OpenAI\nfrom langchain.chains import RetrievalQA\n\nDB_DIR = 'rag_db'\nembeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n\n# Load the same documents as in the basic notebook\nvectordb = Chroma(persist_directory=DB_DIR, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(query, mode='similarity'):\n    if mode == 'mmr':\n        retriever = vectordb.as_retriever(search_type='mmr', search_kwargs={'k':3})\n    elif mode == 'hybrid':\n        retriever = vectordb.as_retriever(search_kwargs={'k':2})\n        # simple hybrid example: rerun with mmr for diversity\n        retriever_mmr = vectordb.as_retriever(search_type='mmr', search_kwargs={'k':1})\n        retriever.search = lambda q: retriever.search(q) + retriever_mmr.search(q)\n    else:\n        retriever = vectordb.as_retriever(search_kwargs={'k':3})\n    qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type='stuff', retriever=retriever)\n    return qa({'query': query})['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in ['similarity','mmr','hybrid']:\n    answer = ask('Which pets are good for apartments?', mode=mode)\n    print(f'--- {mode} ---')\n    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity often retrieves the most relevant documents but may include redundancy. MMR tries to diversify results, while the hybrid approach combines them. Timings and token counts will vary depending on the dataset size."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
